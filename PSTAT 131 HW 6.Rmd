---
title: "PSTAT 131 HW 6"
author: "Raymond Lee"
date: '2022-05-19'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidymodels)
tidymodels_prefer()
library(tidyverse)
library(janitor)
library(rpart.plot)
library(randomForest)
library(xgboost)
library(ranger)
library(vip)

pokemon = read.csv("pokemon.csv")
```

1. 
```{r}
pokemon = clean_names(pokemon)
pokemon = filter(pokemon, type_1 == 'Bug' | type_1 == 'Fire' | type_1 == 'Grass' | type_1 == 'Normal' | 
                   type_1 == 'Water' | type_1 == 'Psychic')
pokemon$type_1 = factor(pokemon$type_1, levels = c('Bug', 'Fire', 'Grass', 'Normal', 'Water', 'Psychic'))
pokemon$legendary = factor(pokemon$legendary, levels = c('True', 'False'))

set.seed(1114)
pokemon_split = initial_split(pokemon, prop = .70, strata = type_1)
pokemon_train = training(pokemon_split)
pokemon_test = testing(pokemon_split)

pokemon_folds = vfold_cv(pokemon_train, v = 5, strata = type_1)

pokemon_recipe = recipe(type_1 ~ legendary + generation + sp_atk + attack + speed + defense + 
                          hp + sp_def, data = pokemon_train) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_normalize(all_predictors())
```

2.
```{r}
library(corrplot)

corrplot(cor(Filter(is.numeric, pokemon_train)), method = 'color')
```
I made a correlation matrix for all continuous variables. There seems to be fairly strong correlation between total and all of the stats. There also seems to be a fairly strong correlation between sp_def and defense. Generation has a weak correlation with all of the stats. These relationships make sense to me because higher stats would lead to a higher total, and pokemon with good defense will most likely also have good special defense.

3.
```{r}
tree_spec <- decision_tree() %>%
  set_engine("rpart")

class_tree_spec <- tree_spec %>%
  set_mode("classification")

class_tree_wf <- workflow() %>%
  add_model(class_tree_spec %>% set_args(cost_complexity = tune())) %>%
  add_recipe(pokemon_recipe)

param_grid <- grid_regular(cost_complexity(range = c(-3, -1)), levels = 10)

tune_res <- tune_grid(class_tree_wf, resamples = pokemon_folds, 
                      grid = param_grid, metrics = metric_set(roc_auc))
autoplot(tune_res)
```
ROC_AUC starts decreasing after little past a complexity penalty of 0.01. A single decision tree performs best with a fairly large complexity penalty of a little past 0.01.

4. 
```{r}
tune_res_metrics = collect_metrics(tune_res)
arrange(tune_res_metrics, desc(mean))
```
The best-performing pruned decision tree on the folds has a mean ROC_AUC of 0.6482470. 

5.
```{r}
best_complexity <- select_best(tune_res)

class_tree_final <- finalize_workflow(class_tree_wf, best_complexity)

class_tree_final_fit <- fit(class_tree_final, data = pokemon_train)

class_tree_final_fit %>%
  extract_fit_engine() %>%
  rpart.plot()
```

6.
```{r}
rand_forest_spec <- rand_forest(mtry = tune(), trees = tune(), min_n = tune()) %>%
  set_engine("ranger", importance = 'impurity') %>%
  set_mode("classification")
```
mtry is the number of predictors that will be randomly sampled at each split when creating the tree models. trees number of trees contained in the ensemble. min_n is the minimum number of data points in a node that are required for the node to be split further.

```{r}
rand_forest_grid = grid_regular(mtry(range = c(1, 8)), trees(range = c(1, 8)), 
                                min_n(range = c(1, 8)), levels = 8)
```
mtry cannot be greater than 8 because our model has 8 predictors. mtry = 8 represents a bagging model.

7.
```{r}
rand_forest_wf = workflow() %>%
  add_model(rand_forest_spec) %>%
  add_recipe(pokemon_recipe)

rand_forest_tune_res <- tune_grid(
  rand_forest_wf, 
  resamples = pokemon_folds, 
  grid = rand_forest_grid, 
  metrics = metric_set(roc_auc)
)

autoplot(rand_forest_tune_res)
```

8.
```{r}
rf_tune_res_metrics = collect_metrics(rand_forest_tune_res)
arrange(rf_tune_res_metrics, desc(mean))
```
The best-performing random forest model on the folds has a mean ROC_AUC of 0.6953591.

9.
```{r}
best_rf = select_best(rand_forest_tune_res, metric = 'roc_auc')
best_rand_forest_spec <- rand_forest(mtry = 6, trees = 6, min_n = 8) %>%
  set_engine("ranger", importance = 'impurity') %>%
  set_mode("classification")
best_rf_fit = fit(best_rand_forest_spec, formula = type_1 ~ legendary + generation + sp_atk + attack + speed + defense + 
                          hp + sp_def, data = pokemon_train)
vip(best_rf_fit)
```
sp_atk is the most important, and legendary is the least important. In the last homework, I thought perhaps each pokemon type has certain stats that are significantly different from other types (so each type is distinct), so this does make some sense. This suggests that sp_atk values are most important when determining a pokemon's primary type. It also makes sense that a pokemon's legendary status would not be strongly related to its primary type. 

10. 
```{r}
boost_spec <- boost_tree(trees = tune(), tree_depth = 8) %>%
  set_engine("xgboost") %>%
  set_mode("classification")

boost_grid = grid_regular(trees(range = c(10, 2000)), levels = 10)

boost_wf = workflow() %>%
  add_model(boost_spec) %>%
  add_recipe(pokemon_recipe)

boost_tune_res <- tune_grid(
  boost_wf, 
  resamples = pokemon_folds, 
  grid = boost_grid, 
  metrics = metric_set(roc_auc)
)

autoplot(boost_tune_res)
```
The ROC_AUC is highest at just below 250 trees. 

```{r}
boost_tune_res_metrics = collect_metrics(boost_tune_res)
arrange(boost_tune_res_metrics, desc(mean))
```
The best-performing boosted tree model on the folds has a mean ROC_AUC of 0.6933468.

11. 
```{r}
best_performing_models = c('pruned tree', 'random forest', 'boosted tree')
roc_auc = c(0.6482470, 0.6953591, 0.6933468)
table = data.frame(best_performing_models, roc_auc)
table
```
Random forest performed the best on the folds. 

```{r}
rf_final = finalize_workflow(rand_forest_wf, best_rf)
rf_final_fit = fit(rf_final, data = pokemon_test)
```

```{r}
predicted_data = augment(rf_final_fit, new_data = pokemon_test) %>% 
  select(type_1, starts_with('.pred'))
predicted_data %>% roc_auc(type_1, .pred_Bug:.pred_Psychic)
```
The AUC value of the best performing model on the testing set is 0.9785463.

```{r}
predicted_data %>% roc_curve(type_1, .pred_Bug:.pred_Psychic) %>% 
  autoplot()
```

```{r}
predicted_data %>% conf_mat(truth = type_1, estimate = .pred_class) %>% 
  autoplot(type = 'heatmap')
```
The model predicts normal and water types the best. It predicts fire types the worst. 


